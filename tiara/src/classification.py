import gzip
from contextlib import suppress
from typing import Dict, Iterator, List, Tuple, Union

import numpy as np
import torch
from Bio.SeqIO.FastaIO import SimpleFastaParser
from joblib import Parallel, delayed
from skorch import NeuralNetClassifier
from tqdm import tqdm

from tiara.src.models import NNet1, NNet2
from tiara.src.prediction import Prediction, SingleResult
from tiara.src.transformations import TfidfWeighter, Transformer
from tiara.src.utilities import chop, parse_params, time_context_manager


def fun(seq, layer, transformer, fragment_len):
    chopped = chop(seq, fragment_len)
    return transformer.transform(chopped)


allowed_letters = set("ACGT")


class Classification:
    """Class that performs classification given neural net and tf-idf models provided.

    Methods
    -------
        classify: classifies an entire fasta file
    """

    def __init__(
        self,
        min_len: int,
        nnet_weights: List[str],
        params: List[Union[Dict[str, int], str]],
        tfidf: List[str],
        threads: int = 1,
        models=(NNet1, NNet2),
    ):
        """Init method.

        Parameters
        ----------
            min_len: minimal length of the sequence to classify
            nnet_weights: a list of paths to nnet weights (generated by skorch for the nnet provided)
            params: either a list of dicts containing neural net params such as number of nodes in hidden layers
                and other parameters such as fragment lenth, kmer length etc,
                or a list of filepaths to .csv files containing parameters
                refer to utilities.parse_params docstring for a specific example
            tfidf: a list of filepaths to tf-idf model
            models: an iterable of torch model classes describing model used
        """
        self.threads = threads
        self.params = [
            parse_params(param) if isinstance(param, str) else param for param in params
        ]
        self.nnets = []
        for model, nnet_weight, params_dict in zip(models, nnet_weights, self.params):
            params_filtered = {
                key: value
                for key, value in params_dict.items()
                if key not in ["k", "fragment_len", "prob_cutoff", "fname"]
            }
            params_filtered.update({"dim_in": 4 ** params_dict["k"]})
            module = model(**params_filtered)
            net = NeuralNetClassifier(module, lr=0.0001, criterion=torch.nn.NLLLoss)
            net.initialize()
            net.load_params(f_params=nnet_weight)
            self.nnets.append(net)
        self.transformers = [
            TfidfWeighter.load_params(tfidf_param_folder)
            for tfidf_param_folder in tfidf
        ]
        self.min_len = min_len
        self.layers = len(nnet_weights)
        self.predictors = [
            Prediction(
                prob_cutoff=self.params[layer]["prob_cutoff"],
                layer=layer,
                nnet=self.nnets[layer],
                fragment_len=self.params[layer]["fragment_len"],
                k=self.params[layer]["k"],
                tnf=self.transformers[layer],
                transformer=Transformer(
                    fragment_len=self.params[layer]["fragment_len"],
                    k=self.params[layer]["k"],
                    model=self.transformers[layer],
                ),
            )
            for layer in range(self.layers)
        ]

    def _sequence_generator(self, sequences_fname: str) -> Iterator[Tuple[str, str]]:
        """Memory-efficient generator that yields sequences from a FASTA file.

        Parameters
        ----------
            sequences_fname: path to FASTA file (can be gzipped)

        Yields
        ------
            (description, sequence) tuples
        """
        if sequences_fname.endswith(".gz"):
            with gzip.open(sequences_fname, "rt") as sequences_handle:
                for desc, seq in SimpleFastaParser(sequences_handle):
                    if len(seq) >= self.min_len:
                        yield desc, seq
        else:
            with open(sequences_fname, "r") as sequences_handle:
                for desc, seq in SimpleFastaParser(sequences_handle):
                    if len(seq) >= self.min_len:
                        yield desc, seq

    def _transform_batch(
        self, sequences: List[Tuple[str, str]], layer: int, verbose: bool = False
    ) -> Iterator[Tuple[str, str, np.ndarray]]:
        """Transform a batch of sequences using parallel processing.

        Parameters
        ----------
            sequences: list of (description, sequence) tuples
            layer: which predictor layer to use
            verbose: whether to show progress bar

        Yields
        ------
            (description, sequence, transformation) tuples
        """
        do = delayed(fun)
        executor = Parallel(n_jobs=self.threads)

        descs = [x[0] for x in sequences]
        seqs = [x[1] for x in sequences]

        tasks = (
            do(
                seq,
                layer,
                self.predictors[layer].transformer,
                self.params[layer]["fragment_len"],
            )
            for seq in seqs
        )

        cont_manager = (
            time_context_manager(f"Calculating layer {layer} sequence representations")
            if verbose
            else suppress()
        )

        with cont_manager:
            transformations = executor(tasks)

        for desc, seq, trans in zip(descs, seqs, transformations):
            yield desc, seq, trans

    def _predict_batch(
        self,
        transformed_records: Iterator[Tuple[str, str, np.ndarray]],
        layer: int,
        verbose: bool = False,
    ) -> List[SingleResult]:
        """Make predictions on a batch of transformed records.

        Parameters
        ----------
            transformed_records: iterator of (description, sequence, transformation) tuples
            layer: which predictor layer to use
            verbose: whether to show progress bar

        Returns
        -------
            predictions: list of SingleResult objects
        """
        predictions = []

        if verbose:
            print(f"Performing layer {layer} classification.")
            iterator = tqdm(transformed_records)
        else:
            iterator = transformed_records

        for desc, seq, bow in iterator:
            prediction = self.predictors[layer].make_prediction((desc, seq, bow))
            predictions.append(prediction)

        return predictions

    def classify(
        self, sequences_fname: str, verbose=False, batch_size: int = 1000
    ) -> List[SingleResult]:
        """Perform a two-step classification with memory-efficient streaming.

        Parameters
        ----------
            sequences_fname : a path to fasta file to classify
            verbose : whether to show progress information
            batch_size : number of sequences to process in each batch

        Returns
        -------
            predictions: a list of SingleResult objects
        """
        all_predictions = []

        # Process sequences in batches
        batch = []
        for desc, seq in self._sequence_generator(sequences_fname):
            batch.append((desc, seq))

            if len(batch) >= batch_size:
                # Process first stage on this batch
                stage1_results = self._process_batch_stage1(batch, verbose)

                # Separate results and collect stage 2 candidates
                stage2_candidates = []
                for prediction in stage1_results:
                    if prediction.cls[0] == "organelle":
                        stage2_candidates.append(prediction)
                    else:
                        all_predictions.append(prediction)

                # Process stage 2 if we have candidates
                if stage2_candidates:
                    stage2_results = self._process_batch_stage2(
                        stage2_candidates, verbose
                    )
                    all_predictions.extend(stage2_results)

                batch = []

        # Process remaining sequences
        if batch:
            stage1_results = self._process_batch_stage1(batch, verbose)

            stage2_candidates = []
            for prediction in stage1_results:
                if prediction.cls[0] == "organelle":
                    stage2_candidates.append(prediction)
                else:
                    all_predictions.append(prediction)

            if stage2_candidates:
                stage2_results = self._process_batch_stage2(stage2_candidates, verbose)
                all_predictions.extend(stage2_results)

        return all_predictions

    def _process_batch_stage1(
        self, batch: List[Tuple[str, str]], verbose: bool = False
    ) -> List[SingleResult]:
        """Process first stage classification for a batch of sequences.

        Parameters
        ----------
            batch: list of (description, sequence) tuples
            verbose: whether to show progress

        Returns
        -------
            predictions: list of SingleResult objects from stage 1
        """
        # Transform sequences
        transformed = list(self._transform_batch(batch, layer=0, verbose=verbose))

        # Make predictions
        predictions = self._predict_batch(iter(transformed), layer=0, verbose=verbose)

        return predictions

    def _process_batch_stage2(
        self, stage1_results: List[SingleResult], verbose: bool = False
    ) -> List[SingleResult]:
        """Process second stage classification for sequences classified as 'organelle'.

        Parameters
        ----------
            stage1_results: list of SingleResult objects from stage 1 that need stage 2 classification
            verbose: whether to show progress

        Returns
        -------
            predictions: list of SingleResult objects with stage 2 classification
        """
        # Prepare batch for stage 2
        batch = [(record.desc, record.seq) for record in stage1_results]

        # Transform sequences
        transformed = list(self._transform_batch(batch, layer=1, verbose=verbose))

        # Make predictions
        stage2_results = self._predict_batch(
            iter(transformed), layer=1, verbose=verbose
        )

        # Merge stage 1 and stage 2 results
        final_results = []
        for stage1, stage2 in zip(stage1_results, stage2_results):
            assert stage1.desc == stage2.desc, "Descriptions not the same"
            assert stage1.seq == stage2.seq, "Sequences not the same"
            final_results.append(
                SingleResult(
                    desc=stage1.desc,
                    seq=stage1.seq,
                    cls=[stage1.cls[0], stage2.cls[1]],
                    probs=[stage1.probs[0], stage2.probs[1]],
                )
            )

        return final_results
